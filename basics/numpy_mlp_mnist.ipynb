{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(a, num_classes):\n",
    "  return np.squeeze(np.eye(num_classes)[a.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images().reshape(-1,784)\n",
    "train_labels = mnist.train_labels()\n",
    "train_labels = one_hot(train_labels,10)\n",
    "\n",
    "test_images = mnist.test_images().reshape(-1,784)\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(targets, predictions , epsilon=1e-12):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    batch_size = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions+epsilon))/batch_size   \n",
    "    return ce\n",
    "\n",
    "def softmax_cross_entropy_grad(targets, predictions):\n",
    "    batch_size = predictions.shape[0]\n",
    "    grad = -(targets-predictions)/batch_size\n",
    "    return grad\n",
    "\n",
    "def softmax(predictions):\n",
    "    predictions=predictions-np.max(predictions,axis=1,keepdims=True)  # dodging numerical overflows\n",
    "    predictions=np.exp(predictions)\n",
    "    return predictions/(np.sum(predictions,axis=1,keepdims=True))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_batch =  [train_images[i:i + 256] for i in range(0, len(train_images), 256)] #  batch len = 256 \n",
    "train_labels_batch = train_img =  [train_labels[i:i + 256] for i in range(0, len(train_labels), 256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 784\n",
    "layers_width=[256,256,10]\n",
    "W = []\n",
    "b = []\n",
    "for i in range(len(layers_width)):\n",
    "    if len(W)==0:\n",
    "        W.append(0.01 * np.random.rand(input_shape,layers_width[i]))\n",
    "    else:\n",
    "        W.append(0.01 * np.random.rand(layers_width[i-1],layers_width[i]))\n",
    "    b.append(np.zeros((1,layers_width[i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:03<00:27,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.36499092145624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:06<00:25,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.21546660655528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:09<00:21,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.096770043747696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:12<00:19,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.833352534167933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:17<00:18,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.27503439403027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:21<00:14,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.096770043747696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:25<00:11,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.998645619007185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:29<00:07,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.378264643204812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:33<00:03,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.676570516363473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:36<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.944012679763881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "epochs=10\n",
    "lr = 0.00001\n",
    "for i in tqdm(range(epochs)):\n",
    "    for batch_idx in range(len(train_images_batch)):\n",
    "        img_batch=train_images_batch[i]\n",
    "        label_batch=train_labels_batch[i]\n",
    "\n",
    "        Z=[]  #pre-activation values\n",
    "        A=[]  #post-activation values\n",
    "\n",
    "        for i in range(len(W)):\n",
    "            if i == 0:\n",
    "                z=img_batch @ W[i] +b[i]\n",
    "            else:\n",
    "                z = A[i-1] @ W[i] + b[i]\n",
    "            \n",
    "            if i!=len(W)-1:\n",
    "                a = relu(z)\n",
    "            else:\n",
    "                a = softmax(z)\n",
    "            Z.append(z)\n",
    "            A.append(a)\n",
    "        # print(Z)\n",
    "        dW=len(W)*[None]\n",
    "        db = len(b) *[None]\n",
    "        dL_dz = softmax_cross_entropy_grad(label_batch,A[-1])\n",
    "\n",
    "        for i in range(len(W)-1,-1,-1):\n",
    "            db[i] = np.sum(dL_dz, axis=0, keepdims=True)\n",
    "            if i==0:\n",
    "                dW[i] =  img_batch.T @ dL_dz\n",
    "                break\n",
    "            else:\n",
    "                dW[i] =  A[i-1].T @ dL_dz\n",
    "\n",
    "            dL_da = dL_dz @ W[i].T\n",
    "            dL_da[Z[i-1]<=0]=0           #dL/dz = dL/da * da/dz    #da/dz = (0 if z<0) (1 if z>0)\n",
    "            dL_dz=dL_da    \n",
    "        \n",
    "        for i in range(len(W)):\n",
    "            W[i]+= -lr*dW[i] + 1e-3*W[i]\n",
    "            b[i]+= -lr*db[i] + 1e-3*b[i]\n",
    "    print(cross_entropy_loss(label_batch,  A[-1]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=test_images\n",
    "for i in range(len(W)):\n",
    "    z = a @ W[i] +b[i]\n",
    "    if i!=len(W)-1:\n",
    "        a = relu(z)\n",
    "    else:\n",
    "        a= softmax(z)\n",
    "preds = np.argmax(a,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 0, 1, ..., 4, 8, 6], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

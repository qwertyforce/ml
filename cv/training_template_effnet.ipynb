{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "import numpy as np\n",
    "\n",
    "torch.set_float32_matmul_precision('high')\n",
    "device=\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_default_model():\n",
    "    model = timm.create_model('tf_efficientnetv2_b1', pretrained=True,drop_path_rate=0.2,drop_rate=0.2)\n",
    "    model.classifier=torch.nn.Linear(1280,1)\n",
    "\n",
    "    # for param in model.parameters():  #for freezing weights\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # for blk in [model.classifier, model.global_pool,model.conv_head,model.blocks[-1],model.blocks[-2],model.blocks[-3]]:\n",
    "    #     for param in blk.parameters():\n",
    "    #         param.requires_grad = True\n",
    "\n",
    "    # for module in model.modules():\n",
    "    #     if isinstance(module, torch.nn.BatchNorm2d):\n",
    "    #         if hasattr(module, 'weight'):\n",
    "    #             module.weight.requires_grad_(False)\n",
    "    #         if hasattr(module, 'bias'):\n",
    "    #             module.bias.requires_grad_(False)\n",
    "    #         module.eval()\n",
    "    model = model.to(device)\n",
    "    # model=torch.compile(model) #cant save model with this\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_default_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os \n",
    "import random\n",
    "\n",
    "def read_img_file(f):\n",
    "    img = Image.open(f)\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "_transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "\n",
    "_transform_w_resize=transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths_labels,resize=False):\n",
    "        self.image_paths_labels = image_paths_labels\n",
    "        self.resize=resize\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths_labels[idx][0]\n",
    "        label = self.image_paths_labels[idx][1]\n",
    "        try:\n",
    "            img = read_img_file(img_path)\n",
    "            img = np.array(img)\n",
    "            # img = all_transforms[0](image=img)[\"image\"] #online augmentation\n",
    "            if self.resize:\n",
    "                im = _transform_w_resize(img)\n",
    "            else:\n",
    "                img = _transform(img)\n",
    "            return (img, label)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"error reading {img_path}\")\n",
    "\n",
    "\n",
    "image_paths_and_classes = []\n",
    "\n",
    "for file_name in os.listdir(\"./train/no_watermark/\"):\n",
    "    image_paths_and_classes.append((\"./train/no_watermark/\"+file_name, 0.0))\n",
    "\n",
    "for file_name in os.listdir(\"./train/watermark/\"):\n",
    "    image_paths_and_classes.append((\"./train/watermark/\"+file_name, 1.0))\n",
    "\n",
    "# image_paths_and_classes=[]\n",
    "# for file_name in os.listdir(\"./train_generated/no_watermark/\"):\n",
    "#     image_paths_and_classes.append((\"./train_generated/no_watermark/\"+file_name, 0.0))\n",
    "\n",
    "# for file_name in os.listdir(\"./train_generated/watermark/\"):\n",
    "#     image_paths_and_classes.append((\"./train_generated/watermark/\"+file_name, 1.0))\n",
    "\n",
    "random.shuffle(image_paths_and_classes)\n",
    "training = image_paths_and_classes\n",
    "\n",
    "testing = []\n",
    "for file_name in os.listdir(\"./test/no_watermark/\"):\n",
    "    testing.append((\"./test/no_watermark/\"+file_name, 0.0))\n",
    "\n",
    "for file_name in os.listdir(\"./test/watermark/\"):\n",
    "    testing.append((\"./test/watermark/\"+file_name, 1.0))\n",
    "\n",
    "# training.extend(image_paths_and_classes[:int(len(image_paths_and_classes)*0.8)])\n",
    "# random.shuffle(training)\n",
    "\n",
    "# testing2 = image_paths_and_classes[int(len(image_paths_and_classes)*0.8):]   #0.2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=48\n",
    "train_dataset = CustomDataset(training)\n",
    "test_dataset = CustomDataset(testing)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True,num_workers=2, prefetch_factor=4,pin_memory=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE,shuffle=True,num_workers=2, prefetch_factor=4,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from timeit import default_timer as timer\n",
    "from statistics import mean\n",
    "from torch.cuda.amp import GradScaler\n",
    "from torch import autocast\n",
    "import optuna\n",
    "import wandb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#wandb = None  #to disable wandb\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(trial=None,train_params={\"lr\":1e-5,\"epochs\":3}):\n",
    "    lr, epochs = train_params[\"lr\"], train_params[\"epochs\"]\n",
    "    # warmup_steps, weight_decay = train_params[\"warmup_steps\"], train_params[\"weight_decay\"]\n",
    "    \n",
    "    if wandb:\n",
    "        wandb.init(project=\"effnet_b0_watermark\", entity=\"qwertyforce\",reinit=True)\n",
    "        wandb.config.update({\n",
    "            \"learning_rate\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            })\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr) \n",
    "    scheduler = None\n",
    "    # num_warmup_steps = int((len(train_dataloader)) * warmup_steps)\n",
    "    # num_training_steps = len(train_dataloader)* 5\n",
    "    # scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    loss_train=[]\n",
    "    loss_test=[]\n",
    "    acc_test=[]\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss = train_one_epoch(optimizer,criterion,scaler,scheduler)\n",
    "        loss_train.append(train_loss)\n",
    "\n",
    "        test_loss,test_acc = test(criterion)\n",
    "        loss_test.append(test_loss)\n",
    "        acc_test.append(test_acc)\n",
    "\n",
    "        if wandb:\n",
    "            wandb.log({\"loss_train\": loss_train[-1],\"epoch\":epoch,\"lr\":optimizer.param_groups[0]['lr']})\n",
    "            wandb.log({\"loss_test\": loss_test[-1],\"epoch\":epoch,\"lr\":optimizer.param_groups[0]['lr']})\n",
    "            wandb.log({\"acc_test\": acc_test[-1],\"epoch\":epoch,\"lr\":optimizer.param_groups[0]['lr']})\n",
    "        # if trial:\n",
    "        #     trial.report(loss_test[-1], epoch)\n",
    "        #     if trial.should_prune():\n",
    "        #         raise optuna.exceptions.TrialPruned()\n",
    "    return loss_train,loss_test,acc_test\n",
    "\n",
    "\n",
    "def train_one_epoch(optimizer,criterion,scaler,scheduler):\n",
    "    model.train()\n",
    "    temp_train_loss=[]\n",
    "    start = timer()\n",
    "    for batch_idx, (data, labels) in enumerate(train_dataloader):\n",
    "        # labels = labels.type(torch.int64)\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model.forward(data)\n",
    "            loss = criterion(outputs,labels.unsqueeze(1)) # remove unsqueeze for CE\n",
    "        \n",
    "        # outputs = model.forward(data)\n",
    "        # loss = criterion(outputs,labels.unsqueeze(1))\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        old_scale = scaler.get_scale()\n",
    "        scaler.update()\n",
    "\n",
    "        if scheduler and old_scale <= scaler.get_scale():\n",
    "            scheduler.step()\n",
    "\n",
    "        temp_train_loss.append(loss.item())\n",
    "        if batch_idx % 100==0:\n",
    "            if wandb:\n",
    "                wandb.log({\"loss_train_batch_idx\": mean(temp_train_loss[-100:]),\"batch_idx\":batch_idx})\n",
    "\n",
    "        if batch_idx % 500==0:\n",
    "            if wandb:\n",
    "                wandb.log({\"loss_test_batch_idx\": test(criterion,partial=True),\"batch_idx\":batch_idx})\n",
    "                model.train()\n",
    "\n",
    "    end = timer()\n",
    "    train_loss = mean(temp_train_loss)\n",
    "    print(f\"Train loss = {train_loss}; epoch_training_time: {end - start}\")\n",
    "    return train_loss\n",
    "    \n",
    "\n",
    "def test(criterion,partial=False):\n",
    "    model.eval()\n",
    "    temp_loss=[]\n",
    "    predictions, true_labels = [], []\n",
    "    for batch_idx, (data, labels) in enumerate(test_dataloader):\n",
    "        with torch.no_grad():\n",
    "            # labels = labels.type(torch.int64)\n",
    "            true_labels.extend(labels)\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            outputs = model.forward(data)\n",
    "            loss = criterion(outputs,labels.unsqueeze(1))  #remove .unsqueeze for CE\n",
    "            temp_loss.append(loss.item())\n",
    "\n",
    "            # preds = torch.argmax(outputs,1).cpu().numpy()  # for CE\n",
    "            preds = np.round(torch.sigmoid(outputs).cpu().numpy())\n",
    "            predictions.extend(preds)\n",
    "        if partial and batch_idx == 100:\n",
    "                return mean(temp_loss)\n",
    "\n",
    "    accuracy = accuracy_score(true_labels,predictions)\n",
    "    test_loss = mean(temp_loss)\n",
    "    print(f\"Test loss = {test_loss}; Test acc = {accuracy}\")\n",
    "    return test_loss, accuracy\n",
    "\n",
    "    # return mean(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.00005,EPOCHS=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# def objective(trial):\n",
    "#     global model\n",
    "#     model = create_default_model()\n",
    "#     model=model.to(\"cuda\")\n",
    "#     lr = trial.suggest_loguniform('learning_rate', 1e-7, 6e-5)\n",
    "#     warmup_steps = trial.suggest_float('warmup_steps', 0.0, 1.5,step=0.1)\n",
    "#     weight_decay = trial.suggest_float('weight_decay', 0.0, 0.05,step=0.005)\n",
    "\n",
    "#     train_params = {\"epochs\":5, \"lr\":lr,\"warmup_steps\":warmup_steps, \"weight_decay\":weight_decay}\n",
    "#     val_loss = train(trial,train_params)\n",
    "#     return val_loss\n",
    "\n",
    "# study_name = \"example-study\"  # Unique identifier of the study.\n",
    "# storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "# study = optuna.create_study(study_name=study_name, storage=storage_name,direction='minimize',pruner=optuna.pruners.HyperbandPruner(), load_if_exists=True)\n",
    "# study.optimize(objective, n_trials=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optuna.visualization import plot_contour\n",
    "# from optuna.visualization import plot_edf\n",
    "# from optuna.visualization import plot_intermediate_values\n",
    "# from optuna.visualization import plot_optimization_history\n",
    "# from optuna.visualization import plot_parallel_coordinate\n",
    "# from optuna.visualization import plot_param_importances\n",
    "# from optuna.visualization import plot_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_slice(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(loss_train)\n",
    "# plt.plot(loss_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_dataset = CustomDataset(testing2)\n",
    "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,shuffle=True,num_workers=2, prefetch_factor=8,pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels= [], []\n",
    "raw_values=[]\n",
    "import numpy as np\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, labels) in enumerate(test_dataloader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        outputs = model.forward(data)\n",
    "        outputs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        raw_values.extend(outputs.reshape(-1))\n",
    "        outputs = np.round(outputs)\n",
    "        predictions.extend(outputs)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "        # loss = criterion(outputs,labels.unsqueeze(1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98      2592\n",
      "         1.0       0.98      0.96      0.97      1959\n",
      "\n",
      "    accuracy                           0.97      4551\n",
      "   macro avg       0.97      0.97      0.97      4551\n",
      "weighted avg       0.97      0.97      0.97      4551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(true_labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m==\u001b[39m\u001b[39m2\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert 1==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20328/20328 [03:03<00:00, 110.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# p = \"/media/qwertyforce/26fbdf65-ba8c-46bc-bbd9-bc503969e854/scenery_cx/scenery/public/images/\"\n",
    "p=\"./no_watermark/\"\n",
    "model.eval()\n",
    "device=\"cuda\"\n",
    "model=model.to(device)\n",
    "# p=\"./test/no_watermark/\"\n",
    "res=[]\n",
    "all_outputs=[]\n",
    "for file_name in tqdm(os.listdir(p)):\n",
    "    if \"_aug_\" in file_name:\n",
    "        continue\n",
    "    img = read_img_file(p+file_name)\n",
    "    img=img.resize((512,512),Image.Resampling.HAMMING)\n",
    "    img = _transform(img).cuda()\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.forward(img)\n",
    "        outputs = torch.sigmoid(outputs).cpu().numpy()\n",
    "        all_outputs.append(outputs[0][0])\n",
    "    if np.round(outputs[0][0]) == 1:\n",
    "        res.append((file_name,outputs[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w8h044.jpg', 0.63842213),\n",
       " ('6618.jpg', 0.79962945),\n",
       " ('1545.jpg', 0.53775936),\n",
       " ('3s5yuq.jpg', 0.61515945),\n",
       " ('7sy9xp.jpg', 0.732666),\n",
       " ('9ors4k.jpg', 0.5848952),\n",
       " ('wvwo95.png', 0.78488404),\n",
       " ('72156k.jpg', 0.74039346),\n",
       " ('ajw189.jpg', 0.5361958),\n",
       " ('2297.jpg', 0.5376779),\n",
       " ('3323.jpg', 0.5000562),\n",
       " ('die66k.jpg', 0.57742304),\n",
       " ('7532.jpg', 0.6067571),\n",
       " ('8446.jpg', 0.54459554),\n",
       " ('5909.jpg', 0.8027137),\n",
       " ('26du47_imgur_N1jwhB1.jpg', 0.78189695),\n",
       " ('9392.jpg', 0.7732248),\n",
       " ('92z39g.jpg', 0.6010037),\n",
       " ('6767.jpg', 0.89132035),\n",
       " ('430.jpg', 0.7065881),\n",
       " ('1320.jpg', 0.57142985),\n",
       " ('3qre3o_imgur_VSiliOm.jpg', 0.56591284),\n",
       " ('dy1ikr.jpg', 0.9142127),\n",
       " ('34.jpg', 0.7617503),\n",
       " ('5y52zn.jpg', 0.9752406),\n",
       " ('4086.jpg', 0.6361611),\n",
       " ('4567.jpg', 0.87832373),\n",
       " ('m596n6.jpg', 0.52296525),\n",
       " ('9571.jpg', 0.92655253),\n",
       " ('232bdt.jpg', 0.55627775),\n",
       " ('8fm8wn.jpg', 0.6622725),\n",
       " ('655.jpg', 0.7661105),\n",
       " ('6367.jpg', 0.54776454),\n",
       " ('2358.jpg', 0.5010291),\n",
       " ('a800gf.jpg', 0.7278174),\n",
       " ('2752.jpg', 0.9285981),\n",
       " ('kyl5oi.jpg', 0.6384929),\n",
       " ('adb9dt_imgur_p5hrtzt.jpg', 0.58213556),\n",
       " ('495.jpg', 0.63593036),\n",
       " ('a6u6ne.jpg', 0.71920574),\n",
       " ('9749.jpg', 0.6037336),\n",
       " ('8951.jpg', 0.8425903),\n",
       " ('1xnhqi.jpg', 0.64777535),\n",
       " ('1242.jpg', 0.50392824),\n",
       " ('1754.jpg', 0.8010775),\n",
       " ('5071.jpg', 0.82180095),\n",
       " ('1039.jpg', 0.7860749),\n",
       " ('7909.jpg', 0.9509537)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(res))\n",
    "res=[el[0] for el in res]\n",
    "import json\n",
    "with open(\"./check_watermarks\",\"w\") as file:\n",
    "    json.dump(res,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, './model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import onnxruntime as onnx\n",
    "# model.eval()\n",
    "# model=model.to(\"cpu\")\n",
    "# x = torch.randn(1, 3, 512, 512, requires_grad=False).cpu()\n",
    "# # torch_out = model(x)\n",
    "# torch.onnx.export(model,                     # model being run\n",
    "#                   x,                            # model input (or a tuple for multiple inputs)\n",
    "#                   \"model.onnx\",              # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,           # store the trained parameter weights inside the model file\n",
    "#                   opset_version=12,             # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,     # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],      # the model's input names\n",
    "#                   output_names = ['output'],\n",
    "#                   dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "#                                 'output' : {0 : 'batch_size'}})    # the model's output names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import onnxruntime\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03666316]]\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# model = torch.load(\"model.pt\")\n",
    "device=\"cpu\"\n",
    "model=model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# inp_arr = torch.randn(32,3,512,512)\n",
    "\n",
    "img = read_img_file(\"./watermark.jpg\")\n",
    "# img.save(\"./orig_wat.jpg\")\n",
    "img=img.resize((512,512),Image.Resampling.LANCZOS)\n",
    "img.save(\"./resized_watermark.jpg\")\n",
    "img = _transform(img).cuda()\n",
    "img.unsqueeze_(0)\n",
    "img = img.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.forward(img)\n",
    "    outputs = torch.sigmoid(outputs).cpu().numpy()\n",
    "print(outputs)\n",
    "# with torch.no_grad():\n",
    "#     out_1 = model(inp_arr)\n",
    "\n",
    "\n",
    "# sess_options = onnxruntime.SessionOptions()\n",
    "# sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "# sess_options.enable_cpu_mem_arena=False\n",
    "# session = onnxruntime.InferenceSession(\"./model.onnx\", sess_options, providers=['CPUExecutionProvider'])\n",
    "# out_2 = session.run([], {'input':input_arr.numpy()})[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
